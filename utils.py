# utils.py
"""
–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import json
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from tabulate import tabulate
from dataclasses import asdict

from backtester import BacktestResults, Trade
from optimizer import OptimizationResult

class ResultsPrinter:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    
    @staticmethod
    def print_backtest_results(results: BacktestResults, 
                              symbol: str = "", 
                              timeframe: str = ""):
        """
        –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
        """
        print("\n" + "=" * 60)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ë–ï–ö–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        if symbol and timeframe:
            print(f"–ü–∞—Ä–∞: {symbol} | –¢–∞–π–º—Ñ—Ä–µ–π–º: {timeframe}")
        print("=" * 60)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = [
            ["üìä –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫", results.total_trades],
            ["‚úÖ –ü—Ä–∏–±—ã–ª—å–Ω—ã—Ö", f"{results.winning_trades} ({results.win_rate:.1%})"],
            ["‚ùå –£–±—ã—Ç–æ—á–Ω—ã—Ö", f"{results.losing_trades} ({(1-results.win_rate):.1%})"],
            ["üí∞ –û–±—â–∏–π P&L", f"{results.total_pnl:.2f} ({results.total_pnl_percent:.2f}%)"],
            ["üìà –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å", f"{results.avg_win:.2f}"],
            ["üìâ –°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫", f"{results.avg_loss:.2f}"],
            ["‚öñÔ∏è Win/Loss Ratio", f"{results.win_loss_ratio:.2f}"],
            ["üìä Sharpe Ratio", f"{results.sharpe_ratio:.2f}"],
            ["üìä Sortino Ratio", f"{results.sortino_ratio:.2f}"],
            ["üí• Max Drawdown", f"{results.max_drawdown:.2f} ({results.max_drawdown_percent:.2f}%)"]
        ]
        
        print(tabulate(metrics, headers=["–ú–µ—Ç—Ä–∏–∫–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ"], 
                      tablefmt="grid", numalign="right"))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º –≤—ã—Ö–æ–¥–∞
        if results.trades_by_exit_reason:
            print("\nüìã –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –≤—ã—Ö–æ–¥–∞:")
            exit_stats = []
            for reason, count in results.trades_by_exit_reason.items():
                percentage = (count / results.total_trades * 100) if results.total_trades > 0 else 0
                exit_stats.append([reason.capitalize(), count, f"{percentage:.1f}%"])
            
            print(tabulate(exit_stats, headers=["–¢–∏–ø –≤—ã—Ö–æ–¥–∞", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "%"],
                          tablefmt="simple", numalign="right"))
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if results.all_trades:
            completed_trades = [t for t in results.all_trades if t.pnl is not None]
            if completed_trades:
                pnl_values = [t.pnl_percent for t in completed_trades]
                
                print("\nüìà –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                add_stats = [
                    ["–ú–µ–¥–∏–∞–Ω–∞ P&L %", f"{np.median(pnl_values):.2f}%"],
                    ["–°—Ç–¥. –æ—Ç–∫–ª. P&L %", f"{np.std(pnl_values):.2f}%"],
                    ["–õ—É—á—à–∞—è —Å–¥–µ–ª–∫–∞", f"{max(pnl_values):.2f}%"],
                    ["–•—É–¥—à–∞—è —Å–¥–µ–ª–∫–∞", f"{min(pnl_values):.2f}%"],
                    ["–ö–æ—ç—Ñ—Ñ. –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è", f"{results.total_pnl_percent / abs(results.max_drawdown_percent):.2f}" 
                     if results.max_drawdown_percent != 0 else "N/A"]
                ]
                
                print(tabulate(add_stats, headers=["–ú–µ—Ç—Ä–∏–∫–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ"],
                              tablefmt="simple", numalign="right"))
        
        print("=" * 60)
    
    @staticmethod
    def save_results_to_json(results: BacktestResults, filepath: str):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        """
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        data = {
            'total_trades': results.total_trades,
            'winning_trades': results.winning_trades,
            'losing_trades': results.losing_trades,
            'win_rate': results.win_rate,
            'total_pnl': results.total_pnl,
            'total_pnl_percent': results.total_pnl_percent,
            'avg_win': results.avg_win,
            'avg_loss': results.avg_loss,
            'win_loss_ratio': results.win_loss_ratio,
            'max_drawdown': results.max_drawdown,
            'max_drawdown_percent': results.max_drawdown_percent,
            'sharpe_ratio': results.sharpe_ratio,
            'sortino_ratio': results.sortino_ratio,
            'trades_by_exit_reason': results.trades_by_exit_reason,
            'trades': []
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–¥–µ–ª–∫–∞—Ö
        for trade in results.all_trades:
            trade_data = {
                'entry_time': trade.entry_time.isoformat() if trade.entry_time else None,
                'exit_time': trade.exit_time.isoformat() if trade.exit_time else None,
                'entry_price': trade.entry_price,
                'exit_price': trade.exit_price,
                'direction': trade.direction,
                'size': trade.size,
                'pnl': trade.pnl,
                'pnl_percent': trade.pnl_percent,
                'exit_reason': trade.exit_reason
            }
            data['trades'].append(trade_data)
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
    
    @staticmethod
    def print_optimization_summary(results: List[OptimizationResult], top_n: int = 5):
        """
        –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞
        """
        print("\n" + "=" * 80)
        print(f"–¢–û–ü-{top_n} –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ô")
        print("=" * 80)
        
        for i, opt_result in enumerate(results[:top_n], 1):
            print(f"\nüèÜ #{i} | Score: {opt_result.optimization_score:.4f}")
            print("-" * 40)
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
            params = opt_result.params
            param_table = [
                ["Neighbors", params.neighbors_count],
                ["Volatility Filter", "‚úì" if params.use_volatility_filter else "‚úó"],
                ["Regime Filter", "‚úì" if params.use_regime_filter else "‚úó"],
                ["EMA Filter", "‚úì" if params.use_ema_filter else "‚úó"],
                ["SMA Filter", "‚úì" if params.use_sma_filter else "‚úó"],
                ["ADX Filter", "‚úì" if params.use_adx_filter else "‚úó"],
                ["Kernel Lookback", params.kernel_lookback],
                ["Kernel Weight", params.kernel_relative_weighting],
                ["Dynamic Exits", "‚úì" if params.use_dynamic_exits else "‚úó"]
            ]
            
            print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
            print(tabulate(param_table, tablefmt="simple"))
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
            res = opt_result.results
            results_table = [
                ["Win Rate", f"{res.win_rate:.1%}"],
                ["Trades", res.total_trades],
                ["Sharpe", f"{res.sharpe_ratio:.2f}"],
                ["P&L %", f"{res.total_pnl_percent:.2f}%"],
                ["Max DD", f"{res.max_drawdown_percent:.2f}%"]
            ]
            
            print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            print(tabulate(results_table, tablefmt="simple"))

class PerformanceAnalyzer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    @staticmethod
    def calculate_monthly_returns(equity_curve: pd.Series) -> pd.Series:
        """
        –†–∞—Å—á–µ—Ç –º–µ—Å—è—á–Ω—ã—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
        
        Args:
            equity_curve: –ö—Ä–∏–≤–∞—è –∫–∞–ø–∏—Ç–∞–ª–∞
            
        Returns:
            Series —Å –º–µ—Å—è—á–Ω—ã–º–∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        """
        monthly = equity_curve.resample('M').last()
        monthly_returns = monthly.pct_change().dropna()
        return monthly_returns
    
    @staticmethod
    def calculate_risk_metrics(returns: pd.Series) -> Dict[str, float]:
        """
        –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Ä–∏—Å–∫–∞
        
        Args:
            returns: Series —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Ä–∏—Å–∫–∞
        """
        metrics = {}
        
        # Value at Risk (95%)
        metrics['var_95'] = np.percentile(returns, 5)
        
        # Conditional Value at Risk (95%)
        var_threshold = metrics['var_95']
        cvar_returns = returns[returns <= var_threshold]
        metrics['cvar_95'] = cvar_returns.mean() if len(cvar_returns) > 0 else 0
        
        # Calmar Ratio (annual return / max drawdown)
        annual_return = returns.mean() * 252
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        max_dd = drawdown.min()
        metrics['calmar_ratio'] = annual_return / abs(max_dd) if max_dd != 0 else 0
        
        # Omega Ratio
        threshold = 0
        gains = returns[returns > threshold] - threshold
        losses = threshold - returns[returns <= threshold]
        
        if len(losses) > 0 and losses.sum() > 0:
            metrics['omega_ratio'] = gains.sum() / losses.sum()
        else:
            metrics['omega_ratio'] = float('inf') if len(gains) > 0 else 0
        
        # Tail Ratio
        percentile_95 = np.percentile(returns, 95)
        percentile_5 = np.percentile(returns, 5)
        metrics['tail_ratio'] = abs(percentile_95 / percentile_5) if percentile_5 != 0 else 0
        
        return metrics
    
    @staticmethod
    def analyze_trade_patterns(trades: List[Trade]) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ —Å–¥–µ–ª–∫–∞—Ö
        
        Args:
            trades: –°–ø–∏—Å–æ–∫ —Å–¥–µ–ª–æ–∫
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
        """
        if not trades:
            return {}
        
        patterns = {}
        
        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—ã–∏–≥—Ä—ã—à–µ–π/–ø—Ä–æ–∏–≥—Ä—ã—à–µ–π
        results_sequence = [1 if t.pnl > 0 else 0 for t in trades if t.pnl is not None]
        
        if results_sequence:
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–µ—Ä–∏—è –≤—ã–∏–≥—Ä—ã—à–µ–π
            max_win_streak = 0
            current_streak = 0
            for result in results_sequence:
                if result == 1:
                    current_streak += 1
                    max_win_streak = max(max_win_streak, current_streak)
                else:
                    current_streak = 0
            patterns['max_win_streak'] = max_win_streak
            
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–µ—Ä–∏—è –ø—Ä–æ–∏–≥—Ä—ã—à–µ–π
            max_loss_streak = 0
            current_streak = 0
            for result in results_sequence:
                if result == 0:
                    current_streak += 1
                    max_loss_streak = max(max_loss_streak, current_streak)
                else:
                    current_streak = 0
            patterns['max_loss_streak'] = max_loss_streak
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏)
        if trades[0].entry_time is not None:
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —á–∞—Å–∞–º –¥–Ω—è
            entry_hours = [t.entry_time.hour for t in trades if t.entry_time]
            if entry_hours:
                hour_distribution = pd.Series(entry_hours).value_counts().to_dict()
                patterns['trades_by_hour'] = hour_distribution
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
            entry_days = [t.entry_time.dayofweek for t in trades if t.entry_time]
            if entry_days:
                day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
                day_distribution = pd.Series(entry_days).value_counts().sort_index()
                patterns['trades_by_day'] = {
                    day_names[i]: count for i, count in day_distribution.items()
                }
            
            # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏
            durations = []
            for trade in trades:
                if trade.entry_time and trade.exit_time:
                    duration = (trade.exit_time - trade.entry_time).total_seconds() / 3600
                    durations.append(duration)
            
            if durations:
                patterns['avg_trade_duration_hours'] = np.mean(durations)
                patterns['median_trade_duration_hours'] = np.median(durations)
        
        return patterns
    
    @staticmethod
    def analyze_optimization_results(results: List[OptimizationResult]) -> Dict[str, Any]:
        """
        –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∞–Ω–∞–ª–∏–∑–æ–º
        """
        if not results:
            return {}
        
        analysis = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –≤ —Ç–æ–ø-10%
        top_10_pct = int(len(results) * 0.1)
        top_results = results[:max(top_10_pct, 10)]
        
        # –ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ —Ç–æ–ø–µ
        param_stats = {
            'neighbors_count': [],
            'use_volatility_filter': [],
            'use_regime_filter': [],
            'use_ema_filter': [],
            'use_sma_filter': [],
            'use_adx_filter': [],
            'kernel_lookback': [],
            'kernel_relative_weighting': [],
            'use_dynamic_exits': []
        }
        
        for r in top_results:
            param_stats['neighbors_count'].append(r.params.neighbors_count)
            param_stats['use_volatility_filter'].append(r.params.use_volatility_filter)
            param_stats['use_regime_filter'].append(r.params.use_regime_filter)
            param_stats['use_ema_filter'].append(r.params.use_ema_filter)
            param_stats['use_sma_filter'].append(r.params.use_sma_filter)
            param_stats['use_adx_filter'].append(r.params.use_adx_filter)
            param_stats['kernel_lookback'].append(r.params.kernel_lookback)
            param_stats['kernel_relative_weighting'].append(r.params.kernel_relative_weighting)
            param_stats['use_dynamic_exits'].append(r.params.use_dynamic_exits)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É –ø–∞—Ä–∞–º–µ—Ç—Ä—É
        analysis['top_params_stats'] = {}
        for param, values in param_stats.items():
            if param.startswith('use_'):
                # –î–ª—è –±—É–ª–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                true_count = sum(values)
                analysis['top_params_stats'][param] = {
                    'true_percentage': true_count / len(values) * 100
                }
            else:
                # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                analysis['top_params_stats'][param] = {
                    'mean': np.mean(values),
                    'median': np.median(values),
                    'std': np.std(values),
                    'most_common': pd.Series(values).mode().iloc[0] if len(pd.Series(values).mode()) > 0 else None
                }
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        param_matrix = []
        scores = []
        win_rates = []
        sharpe_ratios = []
        
        for r in results:
            param_matrix.append([
                r.params.neighbors_count,
                float(r.params.use_volatility_filter),
                float(r.params.use_regime_filter),
                float(r.params.use_ema_filter),
                float(r.params.use_sma_filter),
                float(r.params.use_adx_filter),
                r.params.kernel_lookback,
                r.params.kernel_relative_weighting,
                float(r.params.use_dynamic_exits)
            ])
            scores.append(r.optimization_score)
            win_rates.append(r.results.win_rate)
            sharpe_ratios.append(r.results.sharpe_ratio)
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        param_df = pd.DataFrame(param_matrix, columns=[
            'neighbors_count', 'use_volatility_filter', 'use_regime_filter',
            'use_ema_filter', 'use_sma_filter', 'use_adx_filter',
            'kernel_lookback', 'kernel_relative_weighting', 'use_dynamic_exits'
        ])
        
        param_df['score'] = scores
        param_df['win_rate'] = win_rates
        param_df['sharpe_ratio'] = sharpe_ratios
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        correlations = param_df.corr()
        analysis['param_correlations'] = {
            'with_score': correlations['score'].drop('score').to_dict(),
            'with_win_rate': correlations['win_rate'].drop('win_rate').to_dict(),
            'with_sharpe': correlations['sharpe_ratio'].drop('sharpe_ratio').to_dict()
        }
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        analysis['overall_stats'] = {
            'total_combinations_tested': len(results),
            'best_score': results[0].optimization_score if results else 0,
            'worst_score': results[-1].optimization_score if results else 0,
            'avg_score': np.mean(scores),
            'std_score': np.std(scores),
            'avg_win_rate': np.mean(win_rates),
            'avg_sharpe': np.mean(sharpe_ratios),
            'profitable_configs': sum(1 for r in results if r.results.total_pnl > 0),
            'profitable_percentage': sum(1 for r in results if r.results.total_pnl > 0) / len(results) * 100
        }
        
        return analysis
    
    @staticmethod
    def save_analysis(analysis: Dict[str, Any], filepath: str):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–∞–π–ª
        
        Args:
            analysis: –°–ª–æ–≤–∞—Ä—å —Å –∞–Ω–∞–ª–∏–∑–æ–º
            filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        """
        with open(filepath, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò\n")
            f.write("=" * 80 + "\n\n")
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            if 'overall_stats' in analysis:
                f.write("–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
                f.write("-" * 40 + "\n")
                for key, value in analysis['overall_stats'].items():
                    if isinstance(value, float):
                        f.write(f"{key}: {value:.4f}\n")
                    else:
                        f.write(f"{key}: {value}\n")
                f.write("\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if 'top_params_stats' in analysis:
                f.write("–ê–ù–ê–õ–ò–ó –¢–û–ü –ü–ê–†–ê–ú–ï–¢–†–û–í:\n")
                f.write("-" * 40 + "\n")
                for param, stats in analysis['top_params_stats'].items():
                    f.write(f"\n{param}:\n")
                    for stat_name, stat_value in stats.items():
                        if isinstance(stat_value, float):
                            f.write(f"  {stat_name}: {stat_value:.2f}\n")
                        else:
                            f.write(f"  {stat_name}: {stat_value}\n")
                f.write("\n")
            
            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            if 'param_correlations' in analysis:
                f.write("–ö–û–†–†–ï–õ–Ø–¶–ò–ò –ü–ê–†–ê–ú–ï–¢–†–û–í:\n")
                f.write("-" * 40 + "\n")
                
                for metric, correlations in analysis['param_correlations'].items():
                    f.write(f"\n–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ {metric}:\n")
                    sorted_corr = sorted(correlations.items(), 
                                       key=lambda x: abs(x[1]), 
                                       reverse=True)
                    for param, corr in sorted_corr:
                        f.write(f"  {param}: {corr:.3f}\n")
        
        print(f"–ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filepath}")

class DataValidator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    """
    
    @staticmethod
    def validate_ohlcv_data(df: pd.DataFrame) -> tuple[bool, List[str]]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            Tuple (–≤–∞–ª–∏–¥–Ω—ã –ª–∏ –¥–∞–Ω–Ω—ã–µ, —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫)
        """
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        nan_columns = df[required_columns].columns[df[required_columns].isnull().any()].tolist()
        if nan_columns:
            errors.append(f"NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö: {nan_columns}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—á–Ω–æ—Å—Ç–∏ OHLC
        invalid_ohlc = df[
            (df['high'] < df['low']) |
            (df['high'] < df['open']) |
            (df['high'] < df['close']) |
            (df['low'] > df['open']) |
            (df['low'] > df['close'])
        ]
        
        if not invalid_ohlc.empty:
            errors.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ OHLC –¥–∞–Ω–Ω—ã–µ –≤ {len(invalid_ohlc)} —Å—Ç—Ä–æ–∫–∞—Ö")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        negative_prices = df[
            (df['open'] < 0) | 
            (df['high'] < 0) | 
            (df['low'] < 0) | 
            (df['close'] < 0)
        ]
        
        if not negative_prices.empty:
            errors.append(f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω—ã –≤ {len(negative_prices)} —Å—Ç—Ä–æ–∫–∞—Ö")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        if not isinstance(df.index, pd.DatetimeIndex):
            errors.append("–ò–Ω–¥–µ–∫—Å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è DatetimeIndex")
        else:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
            if df.index.duplicated().any():
                errors.append(f"–î—É–±–ª–∏–∫–∞—Ç—ã –≤ –∏–Ω–¥–µ–∫—Å–µ: {df.index.duplicated().sum()} —Å—Ç—Ä–æ–∫")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
            time_diff = df.index.to_series().diff()
            if len(time_diff.value_counts()) > 1:
                errors.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä—è–¥–µ")
        
        is_valid = len(errors) == 0
        
        return is_valid, errors